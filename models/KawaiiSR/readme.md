训练时的思考：

刚刚看到了一个论文：[CVPR 2024 APISR](https://github.com/Kiteretsu77/APISR/)，这个论文提出了一个非常有意思的训练方式：在图像超分辨率时，通过增加图像的线条，从而使得模型可以学到更清晰的线条。这个或许我也可以添加到我的模型中。

目前的考虑是前80%的训练轮数使用交替的方式，训练锐化后的图片与原图像的图片。而后20%的训练则只专心于原图像的训练。但是具体的效果还得在训练的时候看

或许可以在一个预训练的模型上做微调，像伪影判别器一样，分别两个阶段。

同时，也可以先使用isdir数据集（一共有84,991个高质量的图片）与DIV2K数据集（1000个图片）预处理一个超分辨率网络，然后再使用我的动漫图像做细节上的的微调。

设为9w个图片，如果每个图片使用3个下采样算法，这样就是9 * 3 = 27w个数据对了。效果应该会很不错。


目前发现 https://github.com/XPixelGroup/HAT 这个模型还不错，打算就用这个模型当做基础的模型，然后再加一些我自己的想法，当成超分辨率模型了

根据HAT这个论文，模型在训练时要选择`64*64`大小的输入，来生成`128*128`的图片，所以在制作数据集时，将切片设置为`128*128`就足够了

| 资源级别 | VRAM | 建议 LR Patch Size | `embed_dim` | `depths` | `window_size` |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **高配** | >= 24GB | 64x64 | 180 | `(6,6,6,6,6,6)` | 16 |
| **中配** | 12-24GB| 64x64 | 96 - 120 | `(6,6,6,6)` | 8 / 16 |
| **低配** | 8GB | 48x48 | 60 | `(4,4,4)` | 8 |


对于这个超大模型的训练，可以通过以下的方式来训练：


**第一阶段：标准的训练**
*   **目标**：让 `HAT` 和 `ResidualBlock` 协同工作。
*   **做法**：
    1.  在**标准的小尺寸** `patch`上进行学习
*   **优势**：在第一阶段的基础上进行精调，获得一个高性能的基线模型。

**第二阶段：接缝鲁棒性专项训练 (Finetuning for Tiling Robustness )**
*   **目标**：让模型学会处理分块推理带来的伪影，提升在真实大图上的表现。
*   **做法**：
    1.  加载第二阶段训练好的模型。
    2.  切换到**大尺寸训练 `patch`** (例如 256x256 或 512x512)，并大幅降低 `batch_size`。
    3.  在训练中**打开分块推理** (`use_tiling=True`)。
    4.  可以先用固定的 `tile_size` (例如 128) 进行训练，如果资源允许，再尝试实现动态 `tile_size`。
    5.  使用**极小**的学习率（可能比第二阶段还要小）进行短时间的微调。
*   **优势**：这是一个专门的“攻坚”阶段。由于模型已经很强大，我们只需要让它在原有基础上学会“缝合”这个新技能即可。这既能实现你的目标，又避免了在整个训练流程中承受巨大的计算开销。

**结论：**

你的想法**非常正确且具有前瞻性**。它准确地抓住了提升模型在实际应用中鲁棒性的关键。将你的想法作为一个专门的、最后的**微调阶段**，而不是贯穿整个训练过程，会是一个理论上优秀且实践上可行的最佳策略。它融合了效率和最终性能，堪称完美。