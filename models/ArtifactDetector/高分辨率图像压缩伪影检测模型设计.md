> 由 claude 4 sonnet 生成

# 高分辨率图像压缩伪影检测模型

## 1. 项目概述 (Project Overview)

本项目旨在开发一个高效且精准的模型，用于检测高分辨率图像（尤其是二次元风格图像）中的JPEG/WEBP压缩伪影。与传统方法不同，本方案专门设计用于处理任意尺寸的输入图像，而无需进行有损的缩放预处理，从而最大限度地保留伪影的原始特征。

## 2. 核心挑战与设计哲学 (Core Challenge & Design Philosophy)

### 2.1. 核心挑战：本末倒置的预处理

传统的图像分类模型通常要求将输入图像缩放到固定的尺寸（如 `224x224`）。然而，对于伪影检测任务，**缩放操作会严重破坏或改变伪影的微观特征**（如块效应、振铃效应）。这种做法为了适应模型而牺牲了最重要的判别信息，是典型的本末倒置。

### 2.2. 根本矛盾：内容不变性 vs. 伪影敏感性

像 ResNet 这样的预训练模型，其设计初衷是识别图像的**内容**（猫、狗、汽车），并对压缩、噪声等干扰保持**不变性**。而我们的任务恰恰相反：我们需要模型忽略图像内容，并对压缩伪影这类"噪声"**极其敏感**。因此，直接将原始图像喂给标准模型并非最优解。

### 2.3. 设计哲学：分而治之，聚焦伪影

我们采用"**分而治之**"（Divide and Conquer）的策略，并通过特征工程来解决上述矛盾。我们不改变原始图像的分辨率，而是将其视为由多个局部区域（Patches）组成的集合。模型的核心任务是：

1.  **聚焦伪影**：通过预处理技术，从原图中"提取"并放大伪影信号，抑制内容信号。
2.  **局部识别**：在原始分辨率的局部小块（Patch）上，精准识别伪影特征。
3.  **全局聚合**：智能地汇集所有小块的证据，对整张图做出最终的、具有上下文感知的判断。

## 3. 模型架构 (Model Architecture)

本模型采用层级化设计，由输入预处理、图像切片、局部特征提取、全局特征融合和最终分类五个主要部分组成。

### 步骤 1: 输入预处理与特征工程 (Input Preprocessing & Feature Engineering)

**目标**：创建一张"伪影特征图"，帮助模型"划重点"。

我们不直接使用原始 RGB 图像，而是通过以下技术生成一个多通道的输入张量，该张量极大地放大了伪影信号：

*   **Sobel 边缘检测**: 使用 Sobel 算子的 X 和 Y 方向滤波器来检测图像中的边缘信息。压缩伪影往往在边缘处表现得最为明显，特别是块效应和振铃效应。为了匹配后续小波变换的输出尺寸，我们对灰度图像进行了 2x 下采样。

*   **小波变换 (DWT)**: 使用 Haar 小波将灰度图像分解到不同的方向（水平 `LH`、垂直 `HL`、对角线 `HH`）。这为模型提供了结构化的高频细节信息，能够有效捕捉压缩伪影的频域特征。

**融合**：我们将 Sobel X 和 Y 方向的输出（2个通道）和小波变换的三个高频细节子带（3个通道）通过**通道拼接（Channel Concatenation）**的方式，融合成一个 **5 通道**的输入张量，作为模型的最终输入。

### 步骤 2: 图像切片 (Image Patching)

-   **输入**: 上一步生成的 `H x W x 5` 的伪影特征图。
-   **处理**: 在**不缩放**的情况下，将特征图切分为多个 `224x224` 大小的非重叠 patches。对于无法被整除的边缘，采用**零填充(Zero Padding)**策略补齐。
-   **输出**: 一个批次 (Batch) 的数据，形状为 `(N, 5, 224, 224)`，其中 N 是 patch 的总数。

### 步骤 3: 局部特征提取 (Local Feature Extraction)

-   **组件**: 一个预训练的 **ResNet18** 或 **ResNet34** 作为主干网络 (Backbone)。考虑到数据量限制，选择更轻量的模型有助于避免过拟合。所有 patches **共享**同一个 ResNet 的权重。
-   **网络改造**: 为了接收 5 通道的输入，我们将 ResNet 的**第一个卷积层 `conv1` 替换掉**，将其输入通道数从 3 改为 5。对于新增的 2 个通道，我们使用原有 RGB 通道权重的平均值进行智能初始化。
-   **处理**: 将 `N` 个 patches 送入改造后的 ResNet，移除最终的全连接层，得到每个 patch 的特征向量。
-   **输出**: 一个特征集合，形状为 `(N, 512)`，代表了 `N` 个 patch 各自的局部伪影信息。

### 步骤 4: 全局特征融合 (Global Feature Aggregation)

这是将局部证据融合成全局判断的关键步骤。我们提供两种聚合策略：

#### 4.1. 基础方案: 最大池化融合 (Max Pooling Aggregation)

-   **方法**: 对 `(N, 512)` 的特征集合，在 `N` 这个维度上执行最大池化操作：`torch.max(features, dim=0)`。
-   **直觉**: "只要有一个 patch 存在强烈的伪影，就认为整张图有伪影"。这种策略对于稀疏分布的伪影特别有效。
-   **优点**: 实现简单，计算高效，是验证整个流程的绝佳基线。

#### 4.2. 进阶方案: Transformer 融合 (Transformer Aggregation)

-   **组件**: `TransformerAggregator` 类，包含：
    - 可学习的 `[CLS]` 分类令牌
    - 可学习的位置编码（支持最多 500 个 patches）
    - 多层 Transformer Encoder（默认 2 层，8 个注意力头）
-   **方法**: 
    1. 将 `N` 个 patch 向量视为一个序列
    2. 在序列开头添加 `[CLS]` 令牌
    3. 加入位置编码以保留空间信息
    4. 通过 Transformer Encoder 进行自注意力计算
    5. 提取 `[CLS]` 令牌的输出作为全局特征
-   **优点**: 能够学习 patch 之间复杂的空间依赖关系和上下文信息，理论上性能上限更高。

### 步骤 5: 最终分类 (Final Classification)

-   **输入**: 经过融合后得到的单一全局特征向量，形状为 `(1, 512)`。
-   **组件**: 一个两层的多层感知机 (MLP)：
    ```
    Linear(512 → 256) → GeLU → Dropout → Linear(256 → 2)
    ```
-   **输出**: 最终的二分类 logits（`[无伪影, 有伪影]`）。

## 4. 实现特性 (Implementation Features)

### 4.1. 自定义小波变换模块

实现了 `WaveletTransform2D` 类，支持：
- 多种小波基（默认使用 Haar 小波）
- 前向和逆向变换
- 自适应填充以处理任意尺寸输入
- GPU 加速的卷积实现

### 4.2. 两阶段训练支持

模型提供了 `freeze_backbone()` 和 `unfreeze_backbone()` 方法，支持两阶段微调策略：

1.  **阶段一：预热融合器与分类器**
    -   冻结 ResNet 主干网络权重
    -   只训练全局融合模块和分类器
    -   防止随机初始化的新模块破坏预训练权重

2.  **阶段二：端到端微调**
    -   解冻整个网络
    -   使用较低学习率进行端到端微调

### 4.3. 灵活的配置选项

模型支持多种配置：
- **主干网络**: ResNet18 或 ResNet34
- **聚合策略**: 最大池化或 Transformer
- **Patch 大小**: 可调节（默认 224x224）
- **Dropout 率**: 可调节（默认 0.5）

## 5. 项目优势 (Key Advantages)

-   **伪影保真度**: 直接在原始分辨率的特征上进行分析，最大限度地保留了伪影的真实细节。
-   **尺度不变性**: 模型性能不受输入图像的原始尺寸影响，支持任意分辨率输入。
-   **上下文感知**: 通过全局融合模块，模型不仅能看到局部伪影，还能理解伪影在整张图上的分布模式。
-   **高可解释性**: 可以通过分析每个 patch 的特征来定位图中伪影最严重的区域。
-   **任务特化**: 通过 Sobel 滤波和小波变换的特征工程，模型从一开始就被引导关注伪影而非图像内容。
-   **工程友好**: 提供了完整的训练策略支持和灵活的配置选项，便于实际部署和调优。